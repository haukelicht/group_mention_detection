Summary of test set performances of DeBERTa group mention detection classifiers in cross-party transfer experiment. The y-axis indicates performance in terms of the \texttt{seqeval} F1 score of classifiers fine-tuned on annotated manifesto sentences from the Labour and Conservative party and then evaluated on, and successively adapted to sentences from other UK parties' manifestos. Points (line ranges) report the average ($\pm$\,1\,std.\,dev.) of performances of 5 different classifiers fine-tuned with different random seeds. Plot panels indicate whether the classifier was tested in the source domain (i.e., Lab/Con manifestos, left) or the target domain (i.e., DUP, Greens, LibDem, and UKIP manifestos, right). For the ``target'' panel, the x-axis reports whether the classifier fine-tuned on Lab/Con manifestos was evaluated without adapting it to the target texts (0, i.e., ``zero shot'') or, if not, how much labeled sentences were used to adapt the classifier (through continued training) befor evaluation. \emph{Note:} \texttt{seqeval} is the strict metric proposed by \citet{ramshaw_text_1995} and implemented by \citet{nakayama_seqeval_2018}. \label{fig:uk-manifestos_cross-party-transfer_deberta-finetuning_testset}
