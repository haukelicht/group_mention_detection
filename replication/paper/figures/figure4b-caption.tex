Summary of test set performances of XLM-RoBERTa group mention detection classifiers in cross-lingual transfer experiment. The y-axis indicates performance in terms of the \texttt{seqeval} F1 score of classifiers fine-tuned on annotated sentences UK parties' manifestos and then evaluated on, and successively adapted to sentences from German parties' manifestos. Points (line ranges) report the average ($\pm$\,1\,std.\,dev.) of performances of 5 different classifiers fine-tuned with different random seeds. Plot panels indicate whether the classifier was tested in English (the ``source'' language) or the German (the ``target'' language). For the ``German'' panel, the x-axis indicates whether the classifier fine-tuned on English-language manifestos was evaluated without adapting it to the target language (0, i.e., ``zero shot'') or, if not, how much labeled sentences were used to adapt the classifier (through continued training) befor evaluation. \emph{Note:} \texttt{seqeval} is the strict metric proposed by \citet{ramshaw_text_1995} and implemented by \citet{nakayama_seqeval_2018}. \label{fig:manifestos_cross-lingual-transfer_roberta-finetuning_testset}
